"use strict";(globalThis.webpackChunkolocus_docs=globalThis.webpackChunkolocus_docs||[]).push([[3545],{2841:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>l,metadata:()=>a,toc:()=>o});const a=JSON.parse('{"id":"extensions/privacy/differential-privacy","title":"Differential Privacy","description":"Overview","source":"@site/docs/extensions/privacy/differential-privacy.md","sourceDirName":"extensions/privacy","slug":"/extensions/privacy/differential-privacy","permalink":"/docs/extensions/privacy/differential-privacy","draft":false,"unlisted":false,"editUrl":"https://codeberg.org/olocus/protocol/edit/main/docs/extensions/privacy/differential-privacy.md","tags":[],"version":"current","lastUpdatedAt":1764951516000,"frontMatter":{}}');var t=i(4848),r=i(8453);const l={},s="Differential Privacy",c={},o=[{value:"Overview",id:"overview",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Core Components",id:"core-components",level:3},{value:"Privacy Technique Implementation",id:"privacy-technique-implementation",level:3},{value:"Mechanism Implementations",id:"mechanism-implementations",level:2},{value:"Laplace Mechanism",id:"laplace-mechanism",level:3},{value:"Gaussian Mechanism",id:"gaussian-mechanism",level:3},{value:"Exponential Mechanism",id:"exponential-mechanism",level:3},{value:"Advanced Features",id:"advanced-features",level:2},{value:"Privacy Accounting",id:"privacy-accounting",level:3},{value:"Local Differential Privacy",id:"local-differential-privacy",level:3},{value:"Integration with Olocus Core",id:"integration-with-olocus-core",level:2},{value:"Block Payload Implementation",id:"block-payload-implementation",level:3},{value:"Usage Example",id:"usage-example",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Privacy Analysis",id:"privacy-analysis",level:3},{value:"Performance Characteristics",id:"performance-characteristics",level:2},{value:"Benchmarking",id:"benchmarking",level:3},{value:"Performance Targets",id:"performance-targets",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Parameter Selection",id:"parameter-selection",level:3},{value:"Error Handling",id:"error-handling",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"differential-privacy",children:"Differential Privacy"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Differential privacy provides mathematically rigorous privacy guarantees by adding carefully calibrated noise to data or query results. The Olocus Privacy extension implements differential privacy mechanisms to protect individual privacy while preserving statistical utility for data analysis."}),"\n",(0,t.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsx)(n.h3,{id:"core-components",children:"Core Components"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"use olocus_core::measure::{Measurement, Value, Uncertainty};\nuse rand::{Rng, SeedableRng};\nuse rand_distr::{Laplace, Normal, Distribution};\n\n#[derive(Debug, Clone)]\npub struct DifferentialPrivacyConfig {\n    pub epsilon: f64,           // Privacy budget\n    pub delta: f64,             // Failure probability (for (\u03b5,\u03b4)-DP)\n    pub mechanism: DPMechanism,\n    pub sensitivity: f64,       // Global sensitivity\n    pub clipping_bound: Option<f64>,\n}\n\n#[derive(Debug, Clone)]\npub enum DPMechanism {\n    Laplace { scale: f64 },\n    Gaussian { scale: f64 },\n    Exponential { utility_fn: String },\n    Geometric { probability: f64 },\n    // Future: Advanced mechanisms\n    Shuffle,\n    LocalRandomizedResponse,\n}\n\npub struct DifferentialPrivacyProcessor {\n    config: DifferentialPrivacyConfig,\n    rng: rand::rngs::StdRng,\n    privacy_accountant: PrivacyAccountant,\n}\n\n#[derive(Debug, Clone)]\npub struct PrivacyAccountant {\n    pub total_epsilon_used: f64,\n    pub total_delta_used: f64,\n    pub query_log: Vec<QueryRecord>,\n}\n\n#[derive(Debug, Clone)]\npub struct QueryRecord {\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n    pub epsilon_spent: f64,\n    pub delta_spent: f64,\n    pub mechanism_used: String,\n    pub query_type: String,\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"privacy-technique-implementation",children:"Privacy Technique Implementation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'impl PrivacyTechnique for DifferentialPrivacyProcessor {\n    type Input = Vec<Measurement>;\n    type Output = Vec<Measurement>;\n    type Error = DifferentialPrivacyError;\n\n    fn apply(&mut self, data: Self::Input) -> Result<Self::Output, Self::Error> {\n        // Check privacy budget\n        if !self.privacy_accountant.check_budget(self.config.epsilon, self.config.delta) {\n            return Err(DifferentialPrivacyError::PrivacyBudgetExhausted);\n        }\n\n        let noisy_data = match &self.config.mechanism {\n            DPMechanism::Laplace { scale } => {\n                self.apply_laplace_mechanism(data, *scale)?\n            },\n            DPMechanism::Gaussian { scale } => {\n                self.apply_gaussian_mechanism(data, *scale)?\n            },\n            DPMechanism::Exponential { utility_fn } => {\n                self.apply_exponential_mechanism(data, utility_fn)?\n            },\n            DPMechanism::Geometric { probability } => {\n                self.apply_geometric_mechanism(data, *probability)?\n            },\n            _ => return Err(DifferentialPrivacyError::UnsupportedMechanism),\n        };\n\n        // Record privacy expenditure\n        self.privacy_accountant.record_query(QueryRecord {\n            timestamp: chrono::Utc::now(),\n            epsilon_spent: self.config.epsilon,\n            delta_spent: self.config.delta,\n            mechanism_used: format!("{:?}", self.config.mechanism),\n            query_type: "data_release".to_string(),\n        });\n\n        Ok(noisy_data)\n    }\n\n    fn privacy_loss(&self) -> f64 {\n        self.config.epsilon\n    }\n\n    fn utility_metric(&self, original: &Self::Input, privatized: &Self::Output) -> f64 {\n        self.calculate_mean_squared_error(original, privatized)\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"mechanism-implementations",children:"Mechanism Implementations"}),"\n",(0,t.jsx)(n.h3,{id:"laplace-mechanism",children:"Laplace Mechanism"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"impl DifferentialPrivacyProcessor {\n    pub fn apply_laplace_mechanism(\n        &mut self, \n        data: Vec<Measurement>, \n        scale: f64\n    ) -> Result<Vec<Measurement>, DifferentialPrivacyError> {\n        let laplace = Laplace::new(0.0, scale)\n            .map_err(|_| DifferentialPrivacyError::InvalidParameters)?;\n        \n        let mut noisy_data = Vec::with_capacity(data.len());\n        \n        for measurement in data {\n            let noisy_measurement = match measurement.value {\n                Value::Int(val) => {\n                    let noise = laplace.sample(&mut self.rng);\n                    let noisy_val = val as f64 + noise;\n                    \n                    Measurement {\n                        value: Value::Float(noisy_val),\n                        uncertainty: self.create_noise_uncertainty(scale),\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                Value::Float(val) => {\n                    let noise = laplace.sample(&mut self.rng);\n                    \n                    Measurement {\n                        value: Value::Float(val + noise),\n                        uncertainty: self.create_noise_uncertainty(scale),\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                Value::Array(values) => {\n                    let noisy_values = values.iter()\n                        .map(|v| self.add_noise_to_value(v, &laplace))\n                        .collect::<Result<Vec<_>, _>>()?;\n                    \n                    Measurement {\n                        value: Value::Array(noisy_values),\n                        uncertainty: self.create_noise_uncertainty(scale),\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                _ => {\n                    // Non-numeric values can't have Laplace noise added directly\n                    return Err(DifferentialPrivacyError::IncompatibleDataType);\n                }\n            };\n            \n            noisy_data.push(noisy_measurement);\n        }\n        \n        Ok(noisy_data)\n    }\n\n    fn add_noise_to_value(&mut self, value: &Value, laplace: &Laplace<f64>) -> Result<Value, DifferentialPrivacyError> {\n        match value {\n            Value::Int(val) => {\n                let noise = laplace.sample(&mut self.rng);\n                Ok(Value::Float(*val as f64 + noise))\n            },\n            Value::Float(val) => {\n                let noise = laplace.sample(&mut self.rng);\n                Ok(Value::Float(val + noise))\n            },\n            _ => Ok(value.clone()), // Pass through non-numeric values\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"gaussian-mechanism",children:"Gaussian Mechanism"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"impl DifferentialPrivacyProcessor {\n    pub fn apply_gaussian_mechanism(\n        &mut self, \n        data: Vec<Measurement>, \n        scale: f64\n    ) -> Result<Vec<Measurement>, DifferentialPrivacyError> {\n        let normal = Normal::new(0.0, scale)\n            .map_err(|_| DifferentialPrivacyError::InvalidParameters)?;\n        \n        let mut noisy_data = Vec::with_capacity(data.len());\n        \n        for measurement in data {\n            let noisy_measurement = match measurement.value {\n                Value::Float(val) => {\n                    let noise = normal.sample(&mut self.rng);\n                    \n                    Measurement {\n                        value: Value::Float(val + noise),\n                        uncertainty: Uncertainty::Gaussian { \n                            mean: val, \n                            std_dev: scale \n                        },\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                Value::Int(val) => {\n                    let noise = normal.sample(&mut self.rng);\n                    let noisy_val = val as f64 + noise;\n                    \n                    Measurement {\n                        value: Value::Float(noisy_val),\n                        uncertainty: Uncertainty::Gaussian { \n                            mean: noisy_val, \n                            std_dev: scale \n                        },\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                Value::Point2D(x, y) => {\n                    let noise_x = normal.sample(&mut self.rng);\n                    let noise_y = normal.sample(&mut self.rng);\n                    \n                    Measurement {\n                        value: Value::Point2D(x + noise_x as i64, y + noise_y as i64),\n                        uncertainty: Uncertainty::Circular { \n                            radius: scale * 2.0 // 2-sigma confidence\n                        },\n                        provenance: self.add_privacy_provenance(measurement.provenance),\n                        validity: measurement.validity,\n                    }\n                },\n                _ => return Err(DifferentialPrivacyError::IncompatibleDataType),\n            };\n            \n            noisy_data.push(noisy_measurement);\n        }\n        \n        Ok(noisy_data)\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"exponential-mechanism",children:"Exponential Mechanism"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'impl DifferentialPrivacyProcessor {\n    pub fn apply_exponential_mechanism(\n        &mut self,\n        data: Vec<Measurement>,\n        utility_fn: &str,\n    ) -> Result<Vec<Measurement>, DifferentialPrivacyError> {\n        match utility_fn {\n            "histogram_bin_selection" => self.exponential_histogram(data),\n            "median_selection" => self.exponential_median(data),\n            "quantile_selection" => self.exponential_quantile(data),\n            _ => Err(DifferentialPrivacyError::UnknownUtilityFunction(utility_fn.to_string())),\n        }\n    }\n\n    fn exponential_histogram(&mut self, data: Vec<Measurement>) -> Result<Vec<Measurement>, DifferentialPrivacyError> {\n        let numeric_values: Vec<f64> = data.iter()\n            .filter_map(|m| match &m.value {\n                Value::Float(f) => Some(*f),\n                Value::Int(i) => Some(*i as f64),\n                _ => None,\n            })\n            .collect();\n\n        if numeric_values.is_empty() {\n            return Err(DifferentialPrivacyError::InsufficientData);\n        }\n\n        // Define histogram bins\n        let min_val = numeric_values.iter().cloned().fold(f64::INFINITY, f64::min);\n        let max_val = numeric_values.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n        let bin_count = (numeric_values.len() as f64).sqrt().ceil() as usize;\n        let bin_width = (max_val - min_val) / bin_count as f64;\n\n        // Calculate utility scores for each bin (count in bin)\n        let mut bin_utilities = Vec::new();\n        for i in 0..bin_count {\n            let bin_start = min_val + i as f64 * bin_width;\n            let bin_end = bin_start + bin_width;\n            \n            let count = numeric_values.iter()\n                .filter(|&&val| val >= bin_start && val < bin_end)\n                .count();\n            \n            bin_utilities.push((count as f64, bin_start, bin_end));\n        }\n\n        // Apply exponential mechanism\n        let scale = self.config.sensitivity / self.config.epsilon;\n        let probabilities: Vec<f64> = bin_utilities.iter()\n            .map(|(utility, _, _)| (utility / scale).exp())\n            .collect();\n\n        let total_prob: f64 = probabilities.iter().sum();\n        let normalized_probs: Vec<f64> = probabilities.iter()\n            .map(|p| p / total_prob)\n            .collect();\n\n        // Sample from the distribution\n        let selected_bin = self.sample_from_distribution(&normalized_probs);\n        let (_, bin_start, bin_end) = bin_utilities[selected_bin];\n\n        // Return histogram representation\n        let histogram_measurement = Measurement {\n            value: Value::Object([\n                ("bin_start".to_string(), Value::Float(bin_start)),\n                ("bin_end".to_string(), Value::Float(bin_end)),\n                ("selected_via_exponential".to_string(), Value::Bool(true)),\n            ].iter().cloned().collect()),\n            uncertainty: Uncertainty::Exact,\n            provenance: self.create_exponential_provenance(),\n            validity: None,\n        };\n\n        Ok(vec![histogram_measurement])\n    }\n\n    fn sample_from_distribution(&mut self, probabilities: &[f64]) -> usize {\n        let uniform: f64 = self.rng.gen();\n        let mut cumulative = 0.0;\n        \n        for (i, &prob) in probabilities.iter().enumerate() {\n            cumulative += prob;\n            if uniform <= cumulative {\n                return i;\n            }\n        }\n        \n        probabilities.len() - 1 // Fallback to last element\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,t.jsx)(n.h3,{id:"privacy-accounting",children:"Privacy Accounting"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"impl PrivacyAccountant {\n    pub fn new() -> Self {\n        Self {\n            total_epsilon_used: 0.0,\n            total_delta_used: 0.0,\n            query_log: Vec::new(),\n        }\n    }\n\n    pub fn check_budget(&self, epsilon: f64, delta: f64) -> bool {\n        self.total_epsilon_used + epsilon <= MAX_EPSILON_BUDGET &&\n        self.total_delta_used + delta <= MAX_DELTA_BUDGET\n    }\n\n    pub fn record_query(&mut self, record: QueryRecord) {\n        self.total_epsilon_used += record.epsilon_spent;\n        self.total_delta_used += record.delta_spent;\n        self.query_log.push(record);\n    }\n\n    pub fn remaining_budget(&self) -> (f64, f64) {\n        (\n            MAX_EPSILON_BUDGET - self.total_epsilon_used,\n            MAX_DELTA_BUDGET - self.total_delta_used\n        )\n    }\n\n    /// Advanced composition using optimal composition theorem\n    pub fn calculate_composition_bound(&self) -> (f64, f64) {\n        let mut total_epsilon = 0.0;\n        let mut total_delta = 0.0;\n\n        // Apply advanced composition theorem for better bounds\n        for query in &self.query_log {\n            if query.delta_spent > 0.0 {\n                // (\u03b5,\u03b4)-DP composition\n                let epsilon_prime = query.epsilon_spent * \n                    (2.0 * (2.0 * self.query_log.len() as f64).ln() / query.delta_spent).sqrt();\n                total_epsilon += epsilon_prime.min(query.epsilon_spent);\n                total_delta += query.delta_spent;\n            } else {\n                // Pure \u03b5-DP composition\n                total_epsilon += query.epsilon_spent;\n            }\n        }\n\n        (total_epsilon, total_delta)\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"local-differential-privacy",children:"Local Differential Privacy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"pub struct LocalDifferentialPrivacy {\n    pub epsilon: f64,\n    pub mechanism: LocalDPMechanism,\n}\n\n#[derive(Debug, Clone)]\npub enum LocalDPMechanism {\n    RandomizedResponse { probability: f64 },\n    RAPPOR { hash_functions: usize, bloom_bits: usize },\n    UnaryEncoding { domain_size: usize },\n}\n\nimpl LocalDifferentialPrivacy {\n    pub fn randomized_response(&mut self, value: bool, rng: &mut impl Rng) -> bool {\n        let p = (self.epsilon.exp()) / (1.0 + self.epsilon.exp());\n        \n        if rng.gen::<f64>() < p {\n            value // Truth-telling\n        } else {\n            !value // Lie\n        }\n    }\n\n    pub fn unary_encoding_categorical(\n        &mut self, \n        value: usize, \n        domain_size: usize,\n        rng: &mut impl Rng\n    ) -> Vec<bool> {\n        let mut encoded = vec![false; domain_size];\n        encoded[value] = true;\n\n        // Apply randomized response to each bit\n        encoded.iter()\n            .map(|&bit| self.randomized_response(bit, rng))\n            .collect()\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"integration-with-olocus-core",children:"Integration with Olocus Core"}),"\n",(0,t.jsx)(n.h3,{id:"block-payload-implementation",children:"Block Payload Implementation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use olocus_core::{Block, BlockPayload};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DifferentialPrivacyPayload {\n    pub epsilon: f64,\n    pub delta: f64,\n    pub mechanism: String,\n    pub sensitivity: f64,\n    pub data: Vec<Measurement>,\n    pub privacy_metadata: DifferentialPrivacyMetadata,\n    pub accountability: PrivacyAccountingRecord,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DifferentialPrivacyMetadata {\n    pub algorithm: String,\n    pub parameters: serde_json::Value,\n    pub noise_scale: f64,\n    pub utility_loss: f64,\n    pub composition_method: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PrivacyAccountingRecord {\n    pub total_epsilon_used: f64,\n    pub total_delta_used: f64,\n    pub remaining_budget: (f64, f64),\n    pub query_count: usize,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n}\n\nimpl BlockPayload for DifferentialPrivacyPayload {\n    fn payload_type(&self) -> u16 {\n        0x0522 // Privacy extension, differential privacy subtype\n    }\n\n    fn validate(&self) -> Result<(), Box<dyn std::error::Error>> {\n        // Validate privacy parameters\n        if self.epsilon <= 0.0 {\n            return Err("Epsilon must be positive".into());\n        }\n\n        if self.delta < 0.0 || self.delta >= 1.0 {\n            return Err("Delta must be in [0, 1)".into());\n        }\n\n        if self.sensitivity <= 0.0 {\n            return Err("Sensitivity must be positive".into());\n        }\n\n        // Validate privacy budget hasn\'t been exceeded\n        if self.accountability.total_epsilon_used > MAX_EPSILON_BUDGET {\n            return Err("Epsilon budget exceeded".into());\n        }\n\n        if self.accountability.total_delta_used > MAX_DELTA_BUDGET {\n            return Err("Delta budget exceeded".into());\n        }\n\n        // Validate noise scale is appropriate for mechanism\n        let expected_scale = match self.mechanism.as_str() {\n            "laplace" => self.sensitivity / self.epsilon,\n            "gaussian" => self.sensitivity * (2.0 * (1.25 / self.delta).ln()).sqrt() / self.epsilon,\n            _ => return Err("Unknown mechanism".into()),\n        };\n\n        if (self.privacy_metadata.noise_scale - expected_scale).abs() > 0.001 {\n            return Err("Incorrect noise scale for mechanism".into());\n        }\n\n        Ok(())\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"usage-example",children:"Usage Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use olocus_privacy::{DifferentialPrivacyProcessor, DifferentialPrivacyConfig, DPMechanism};\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Configure differential privacy\n    let config = DifferentialPrivacyConfig {\n        epsilon: 1.0,  // Privacy budget\n        delta: 1e-5,   // Failure probability\n        mechanism: DPMechanism::Laplace { \n            scale: 1.0  // Will be recalculated based on sensitivity\n        },\n        sensitivity: 1.0,  // Global sensitivity of the function\n        clipping_bound: Some(10.0),  // Clip values to bound sensitivity\n    };\n\n    let mut processor = DifferentialPrivacyProcessor::new(config)?;\n\n    // Create sensitive location data\n    let location_data = vec![\n        create_location_measurement(37.7749, -122.4194), // San Francisco\n        create_location_measurement(37.7849, -122.4094), // Nearby location\n        create_location_measurement(37.7649, -122.4294), // Another nearby location\n    ];\n\n    // Apply differential privacy\n    let privatized_data = processor.apply(location_data.clone())?;\n\n    // Create differentially private payload\n    let payload = DifferentialPrivacyPayload {\n        epsilon: 1.0,\n        delta: 1e-5,\n        mechanism: "laplace".to_string(),\n        sensitivity: 1.0,\n        data: privatized_data,\n        privacy_metadata: DifferentialPrivacyMetadata {\n            algorithm: "laplace_mechanism".to_string(),\n            parameters: serde_json::json!({\n                "epsilon": 1.0,\n                "delta": 1e-5,\n                "scale": 1.0\n            }),\n            noise_scale: 1.0,\n            utility_loss: processor.utility_metric(&location_data, &privatized_data),\n            composition_method: "basic".to_string(),\n        },\n        accountability: PrivacyAccountingRecord {\n            total_epsilon_used: processor.privacy_accountant.total_epsilon_used,\n            total_delta_used: processor.privacy_accountant.total_delta_used,\n            remaining_budget: processor.privacy_accountant.remaining_budget(),\n            query_count: processor.privacy_accountant.query_log.len(),\n            timestamp: chrono::Utc::now(),\n        },\n    };\n\n    // Create block\n    let block = Block::new(payload)?;\n    println!("Created differentially private block: {}", hex::encode(block.hash()));\n\n    Ok(())\n}\n\nfn create_location_measurement(lat: f64, lon: f64) -> Measurement {\n    use olocus_core::measure::Coordinate;\n    \n    let lat_fixed = Coordinate::latitude_to_fixed(lat);\n    let lon_fixed = Coordinate::longitude_to_fixed(lon);\n    \n    Measurement {\n        value: Value::Point2D(lat_fixed, lon_fixed),\n        uncertainty: Uncertainty::Circular { radius: 10.0 }, // 10m accuracy\n        provenance: Default::default(),\n        validity: None,\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,t.jsx)(n.h3,{id:"privacy-analysis",children:"Privacy Analysis"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'pub struct DifferentialPrivacyAnalysis {\n    pub privacy_guarantee: String,\n    pub composition_bound: (f64, f64),\n    pub attack_resistance: AttackResistance,\n    pub utility_metrics: UtilityMetrics,\n}\n\n#[derive(Debug, Clone)]\npub struct AttackResistance {\n    pub membership_inference: f64,     // Resistance to membership inference\n    pub reconstruction: f64,           // Resistance to reconstruction attacks\n    pub property_inference: f64,       // Resistance to property inference\n}\n\n#[derive(Debug, Clone)]\npub struct UtilityMetrics {\n    pub mean_squared_error: f64,\n    pub signal_to_noise_ratio: f64,\n    pub relative_error: f64,\n    pub statistical_significance: f64,\n}\n\nimpl DifferentialPrivacyProcessor {\n    pub fn analyze_privacy_utility_tradeoff(&self, original: &[Measurement], privatized: &[Measurement]) -> DifferentialPrivacyAnalysis {\n        let composition = self.privacy_accountant.calculate_composition_bound();\n        \n        let attack_resistance = AttackResistance {\n            membership_inference: (-self.config.epsilon).exp(), // DP guarantee\n            reconstruction: self.calculate_reconstruction_resistance(original),\n            property_inference: self.calculate_property_inference_resistance(original),\n        };\n        \n        let utility = UtilityMetrics {\n            mean_squared_error: self.calculate_mean_squared_error(original, privatized),\n            signal_to_noise_ratio: self.calculate_snr(original, privatized),\n            relative_error: self.calculate_relative_error(original, privatized),\n            statistical_significance: self.calculate_statistical_significance(original, privatized),\n        };\n        \n        DifferentialPrivacyAnalysis {\n            privacy_guarantee: format!("({:.3}, {:.2e})-differential privacy", composition.0, composition.1),\n            composition_bound: composition,\n            attack_resistance,\n            utility_metrics: utility,\n        }\n    }\n\n    fn calculate_snr(&self, original: &[Measurement], privatized: &[Measurement]) -> f64 {\n        let signal_power = self.calculate_signal_power(original);\n        let noise_power = self.calculate_noise_power(original, privatized);\n        \n        if noise_power > 0.0 {\n            10.0 * (signal_power / noise_power).log10()\n        } else {\n            f64::INFINITY\n        }\n    }\n\n    fn calculate_statistical_significance(&self, original: &[Measurement], privatized: &[Measurement]) -> f64 {\n        // Perform statistical tests to determine if privatized data\n        // maintains statistical properties of original data\n        self.kolmogorov_smirnov_test(original, privatized)\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"performance-characteristics",children:"Performance Characteristics"}),"\n",(0,t.jsx)(n.h3,{id:"benchmarking",children:"Benchmarking"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'#[cfg(test)]\nmod benchmarks {\n    use super::*;\n    use criterion::{black_box, Criterion};\n\n    pub fn benchmark_laplace_mechanism(c: &mut Criterion) {\n        let config = DifferentialPrivacyConfig {\n            epsilon: 1.0,\n            delta: 0.0,\n            mechanism: DPMechanism::Laplace { scale: 1.0 },\n            sensitivity: 1.0,\n            clipping_bound: None,\n        };\n        \n        let mut processor = DifferentialPrivacyProcessor::new(config).unwrap();\n        \n        for size in [100, 1000, 10000].iter() {\n            let data = generate_numeric_dataset(*size);\n            \n            c.bench_function(&format!("laplace_mechanism_{}", size), |b| {\n                b.iter(|| {\n                    processor.apply(black_box(data.clone())).unwrap()\n                })\n            });\n        }\n    }\n\n    pub fn benchmark_gaussian_mechanism(c: &mut Criterion) {\n        let config = DifferentialPrivacyConfig {\n            epsilon: 1.0,\n            delta: 1e-5,\n            mechanism: DPMechanism::Gaussian { scale: 1.414 },\n            sensitivity: 1.0,\n            clipping_bound: None,\n        };\n        \n        let mut processor = DifferentialPrivacyProcessor::new(config).unwrap();\n        \n        for size in [100, 1000, 10000].iter() {\n            let data = generate_numeric_dataset(*size);\n            \n            c.bench_function(&format!("gaussian_mechanism_{}", size), |b| {\n                b.iter(|| {\n                    processor.apply(black_box(data.clone())).unwrap()\n                })\n            });\n        }\n    }\n\n    pub fn benchmark_exponential_mechanism(c: &mut Criterion) {\n        let config = DifferentialPrivacyConfig {\n            epsilon: 1.0,\n            delta: 0.0,\n            mechanism: DPMechanism::Exponential { \n                utility_fn: "median_selection".to_string() \n            },\n            sensitivity: 1.0,\n            clipping_bound: None,\n        };\n        \n        let mut processor = DifferentialPrivacyProcessor::new(config).unwrap();\n        \n        for size in [100, 1000, 5000].iter() {\n            let data = generate_numeric_dataset(*size);\n            \n            c.bench_function(&format!("exponential_mechanism_{}", size), |b| {\n                b.iter(|| {\n                    processor.apply(black_box(data.clone())).unwrap()\n                })\n            });\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Laplace mechanism"}),": O(n) time, O(1) space per measurement"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gaussian mechanism"}),": O(n) time, O(1) space per measurement"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Exponential mechanism"}),": O(n log n) time for sorting-based utilities"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Target latency"}),": <50ms for 10,000 measurements with Laplace/Gaussian"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"parameter-selection",children:"Parameter Selection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"pub struct DifferentialPrivacyParameterGuide;\n\nimpl DifferentialPrivacyParameterGuide {\n    /// Recommend epsilon values based on data sensitivity\n    pub fn recommend_epsilon(data_sensitivity: DataSensitivity) -> f64 {\n        match data_sensitivity {\n            DataSensitivity::HighlyPersonal => 0.1,     // Medical records, financial data\n            DataSensitivity::Personal => 0.5,           // Demographics, preferences\n            DataSensitivity::SemiPublic => 1.0,         // Aggregated behaviors\n            DataSensitivity::Public => 2.0,             // Public statistics\n        }\n    }\n\n    /// Recommend delta values based on dataset size\n    pub fn recommend_delta(dataset_size: usize) -> f64 {\n        1.0 / (dataset_size as f64 * dataset_size as f64)\n    }\n\n    /// Calculate optimal noise scale for given parameters\n    pub fn calculate_noise_scale(mechanism: &DPMechanism, epsilon: f64, delta: f64, sensitivity: f64) -> f64 {\n        match mechanism {\n            DPMechanism::Laplace { .. } => sensitivity / epsilon,\n            DPMechanism::Gaussian { .. } => {\n                sensitivity * (2.0 * (1.25 / delta).ln()).sqrt() / epsilon\n            },\n            _ => 1.0, // Default fallback\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub enum DataSensitivity {\n    HighlyPersonal,\n    Personal,\n    SemiPublic,\n    Public,\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'#[derive(Debug, thiserror::Error)]\npub enum DifferentialPrivacyError {\n    #[error("Invalid privacy parameters: epsilon={epsilon}, delta={delta}")]\n    InvalidParameters { epsilon: f64, delta: f64 },\n    \n    #[error("Privacy budget exhausted: used {used}, limit {limit}")]\n    PrivacyBudgetExhausted { used: f64, limit: f64 },\n    \n    #[error("Incompatible data type for mechanism")]\n    IncompatibleDataType,\n    \n    #[error("Unsupported mechanism: {0}")]\n    UnsupportedMechanism(String),\n    \n    #[error("Unknown utility function: {0}")]\n    UnknownUtilityFunction(String),\n    \n    #[error("Insufficient data for mechanism")]\n    InsufficientData,\n    \n    #[error("Sensitivity calculation failed: {0}")]\n    SensitivityCalculationFailed(String),\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"This comprehensive implementation provides production-ready differential privacy capabilities within the Olocus Privacy extension, ensuring mathematically rigorous privacy guarantees while maintaining practical utility for real-world applications."})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>s});var a=i(6540);const t={},r=a.createContext(t);function l(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);