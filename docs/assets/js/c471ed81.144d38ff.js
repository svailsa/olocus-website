"use strict";(globalThis.webpackChunkolocus_docs=globalThis.webpackChunkolocus_docs||[]).push([[5112],{8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>l});var i=t(6540);const s={},r=i.createContext(s);function a(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),i.createElement(r.Provider,{value:e},n.children)}},8950:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"extensions/location/clustering","title":"Clustering Algorithms","description":"The Location extension provides multiple clustering algorithms for analyzing spatial-temporal patterns in location data. Each algorithm is optimized for different use cases and data characteristics.","source":"@site/docs/extensions/location/clustering.md","sourceDirName":"extensions/location","slug":"/extensions/location/clustering","permalink":"/docs/extensions/location/clustering","draft":false,"unlisted":false,"editUrl":"https://codeberg.org/olocus/protocol/edit/main/docs/extensions/location/clustering.md","tags":[],"version":"current","lastUpdatedAt":null,"sidebarPosition":3,"frontMatter":{"id":"clustering","title":"Clustering Algorithms","sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Visit Detection","permalink":"/docs/extensions/location/visit-detection"},"next":{"title":"Privacy & Obfuscation","permalink":"/docs/extensions/location/privacy-obfuscation"}}');var s=t(4848),r=t(8453);const a={id:"clustering",title:"Clustering Algorithms",sidebar_position:3},l="Clustering Algorithms",o={},c=[{value:"Overview",id:"overview",level:2},{value:"DBSCAN (Density-Based Spatial Clustering)",id:"dbscan-density-based-spatial-clustering",level:2},{value:"Algorithm Implementation",id:"algorithm-implementation",level:3},{value:"DBSCAN Configuration Examples",id:"dbscan-configuration-examples",level:3},{value:"K-Means Clustering",id:"k-means-clustering",level:2},{value:"Algorithm Implementation",id:"algorithm-implementation-1",level:3},{value:"K-Means Optimization",id:"k-means-optimization",level:3},{value:"OPTICS (Ordering Points To Identify Clustering Structure)",id:"optics-ordering-points-to-identify-clustering-structure",level:2},{value:"Algorithm Implementation",id:"algorithm-implementation-2",level:3},{value:"Cluster Extraction from OPTICS",id:"cluster-extraction-from-optics",level:3},{value:"HDBSCAN (Hierarchical DBSCAN)",id:"hdbscan-hierarchical-dbscan",level:2},{value:"Algorithm Implementation",id:"algorithm-implementation-3",level:3},{value:"Performance Comparison",id:"performance-comparison",level:2},{value:"Algorithm Characteristics",id:"algorithm-characteristics",level:3},{value:"Performance Benchmarks",id:"performance-benchmarks",level:3},{value:"Spatial Indexing",id:"spatial-indexing",level:2},{value:"KD-Tree for Fast Neighbor Queries",id:"kd-tree-for-fast-neighbor-queries",level:3},{value:"Integration Examples",id:"integration-examples",level:2},{value:"Adaptive Clustering",id:"adaptive-clustering",level:3},{value:"Stream Processing",id:"stream-processing",level:3},{value:"Testing &amp; Validation",id:"testing--validation",level:2},{value:"Configuration Recommendations",id:"configuration-recommendations",level:2},{value:"Data Size Guidelines",id:"data-size-guidelines",level:3},{value:"Related Documentation",id:"related-documentation",level:2}];function u(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"clustering-algorithms",children:"Clustering Algorithms"})}),"\n",(0,s.jsx)(e.p,{children:"The Location extension provides multiple clustering algorithms for analyzing spatial-temporal patterns in location data. Each algorithm is optimized for different use cases and data characteristics."}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:"Clustering algorithms group similar locations together to identify:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Significant Places"}),": Frequently visited locations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Movement Patterns"}),": Routes and transitions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Behavioral Insights"}),": Daily routines and habits"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::*;\n\n// Available clustering algorithms\nlet dbscan = ClusteringAlgorithm::DBSCAN {\n    epsilon: 30.0,      // 30m radius\n    min_points: 3,      // Minimum 3 points per cluster\n};\n\nlet kmeans = ClusteringAlgorithm::KMeans {\n    k: 8,               // 8 expected locations\n    max_iterations: 100,\n    convergence_threshold: 1.0,\n};\n\nlet optics = ClusteringAlgorithm::OPTICS {\n    min_points: 3,\n    epsilon: 100.0,\n    xi: 0.05,\n};\n\nlet hdbscan = ClusteringAlgorithm::HDBSCAN {\n    min_cluster_size: 5,\n    min_samples: 3,\n    cluster_selection_epsilon: 0.0,\n};\n"})}),"\n",(0,s.jsx)(e.h2,{id:"dbscan-density-based-spatial-clustering",children:"DBSCAN (Density-Based Spatial Clustering)"}),"\n",(0,s.jsx)(e.p,{children:"DBSCAN is ideal for finding dense clusters of arbitrary shape and handling noise:"}),"\n",(0,s.jsx)(e.h3,{id:"algorithm-implementation",children:"Algorithm Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::dbscan::*;\n\n#[derive(Debug, Clone)]\npub struct DBSCANConfig {\n    pub epsilon: f64,                    // Maximum distance between points (meters)\n    pub min_points: usize,               // Minimum points to form dense region\n    pub distance_metric: DistanceMetric, // Haversine, Euclidean, Manhattan\n}\n\n#[derive(Debug, Clone)]\npub enum DistanceMetric {\n    Haversine,   // Great circle distance for GPS coordinates\n    Euclidean,   // Straight-line distance for projected coordinates\n    Manhattan,   // City-block distance for grid-based movement\n}\n\npub struct DBSCANClusterer {\n    config: DBSCANConfig,\n}\n\nimpl DBSCANClusterer {\n    pub fn cluster(&self, points: &[LocationMeasurement]) -> Result<Vec<Cluster>> {\n        let mut clusters = Vec::new();\n        let mut visited = vec![false; points.len()];\n        let mut cluster_id = 0;\n        \n        for (i, point) in points.iter().enumerate() {\n            if visited[i] {\n                continue;\n            }\n            \n            visited[i] = true;\n            let neighbors = self.find_neighbors(point, points);\n            \n            if neighbors.len() < self.config.min_points {\n                // Mark as noise\n                continue;\n            }\n            \n            // Start new cluster\n            let cluster = self.expand_cluster(\n                i, &neighbors, points, &mut visited, cluster_id\n            )?;\n            clusters.push(cluster);\n            cluster_id += 1;\n        }\n        \n        Ok(clusters)\n    }\n    \n    fn find_neighbors(&self, center: &LocationMeasurement, points: &[LocationMeasurement]) -> Vec<usize> {\n        points.iter().enumerate()\n            .filter_map(|(i, point)| {\n                let distance = self.calculate_distance(center, point);\n                if distance <= self.config.epsilon {\n                    Some(i)\n                } else {\n                    None\n                }\n            })\n            .collect()\n    }\n    \n    fn calculate_distance(&self, p1: &LocationMeasurement, p2: &LocationMeasurement) -> f64 {\n        match self.config.distance_metric {\n            DistanceMetric::Haversine => {\n                Coordinate::haversine_distance(\n                    p1.measurement.value.x(), p1.measurement.value.y(),\n                    p2.measurement.value.x(), p2.measurement.value.y()\n                )\n            },\n            DistanceMetric::Euclidean => {\n                let dx = (p1.measurement.value.x() - p2.measurement.value.x()) as f64 / 10_000_000.0;\n                let dy = (p1.measurement.value.y() - p2.measurement.value.y()) as f64 / 10_000_000.0;\n                ((dx * dx + dy * dy).sqrt()) * 111_320.0 // Approximate meters per degree\n            },\n            DistanceMetric::Manhattan => {\n                let dx = ((p1.measurement.value.x() - p2.measurement.value.x()).abs() as f64) / 10_000_000.0;\n                let dy = ((p1.measurement.value.y() - p2.measurement.value.y()).abs() as f64) / 10_000_000.0;\n                (dx + dy) * 111_320.0\n            }\n        }\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"dbscan-configuration-examples",children:"DBSCAN Configuration Examples"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"// Dense urban environment\nlet urban_dbscan = DBSCANConfig {\n    epsilon: 15.0,                          // Small radius for precise clustering\n    min_points: 5,                          // Higher threshold for dense data\n    distance_metric: DistanceMetric::Haversine,\n};\n\n// Sparse rural environment\nlet rural_dbscan = DBSCANConfig {\n    epsilon: 50.0,                          // Larger radius for GPS variance\n    min_points: 2,                          // Lower threshold for sparse data\n    distance_metric: DistanceMetric::Haversine,\n};\n\n// Indoor positioning with beacons\nlet indoor_dbscan = DBSCANConfig {\n    epsilon: 5.0,                           // High precision indoor\n    min_points: 3,                          // Moderate threshold\n    distance_metric: DistanceMetric::Euclidean,\n};\n\n// Vehicle tracking on roads\nlet vehicle_dbscan = DBSCANConfig {\n    epsilon: 25.0,                          // Road-width tolerance\n    min_points: 4,                          // Filter brief stops\n    distance_metric: DistanceMetric::Haversine,\n};\n"})}),"\n",(0,s.jsx)(e.h2,{id:"k-means-clustering",children:"K-Means Clustering"}),"\n",(0,s.jsx)(e.p,{children:"K-Means partitions data into a predetermined number of clusters:"}),"\n",(0,s.jsx)(e.h3,{id:"algorithm-implementation-1",children:"Algorithm Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::kmeans::*;\n\n#[derive(Debug, Clone)]\npub struct KMeansConfig {\n    pub k: usize,                           // Number of clusters\n    pub max_iterations: usize,              // Maximum iterations\n    pub convergence_threshold: f64,         // Convergence threshold (meters)\n    pub initialization: InitMethod,         // Centroid initialization method\n}\n\n#[derive(Debug, Clone)]\npub enum InitMethod {\n    Random,                                 // Random centroid placement\n    KMeansPlusPlus,                        // K-means++ initialization\n    Forgy,                                 // Forgy method (random points as centroids)\n}\n\npub struct KMeansClusterer {\n    config: KMeansConfig,\n}\n\nimpl KMeansClusterer {\n    pub fn cluster(&self, points: &[LocationMeasurement]) -> Result<KMeansResult> {\n        let mut centroids = self.initialize_centroids(points)?;\n        let mut assignments = vec![0; points.len()];\n        \n        for iteration in 0..self.config.max_iterations {\n            // Assign points to nearest centroid\n            let mut changed = false;\n            for (i, point) in points.iter().enumerate() {\n                let new_assignment = self.find_nearest_centroid(point, &centroids);\n                if assignments[i] != new_assignment {\n                    assignments[i] = new_assignment;\n                    changed = true;\n                }\n            }\n            \n            // Update centroids\n            let new_centroids = self.update_centroids(points, &assignments)?;\n            \n            // Check convergence\n            let max_movement = centroids.iter().zip(new_centroids.iter())\n                .map(|(old, new)| Coordinate::haversine_distance(\n                    old.latitude, old.longitude,\n                    new.latitude, new.longitude\n                ))\n                .fold(0.0, f64::max);\n                \n            centroids = new_centroids;\n            \n            if !changed || max_movement < self.config.convergence_threshold {\n                return Ok(KMeansResult {\n                    centroids,\n                    assignments,\n                    iterations: iteration + 1,\n                    inertia: self.calculate_inertia(points, &centroids, &assignments),\n                });\n            }\n        }\n        \n        Ok(KMeansResult {\n            centroids,\n            assignments,\n            iterations: self.config.max_iterations,\n            inertia: self.calculate_inertia(points, &centroids, &assignments),\n        })\n    }\n    \n    fn initialize_centroids(&self, points: &[LocationMeasurement]) -> Result<Vec<Coordinate>> {\n        match self.config.initialization {\n            InitMethod::Random => self.random_initialization(points),\n            InitMethod::KMeansPlusPlus => self.kmeans_plus_plus_initialization(points),\n            InitMethod::Forgy => self.forgy_initialization(points),\n        }\n    }\n    \n    fn kmeans_plus_plus_initialization(&self, points: &[LocationMeasurement]) -> Result<Vec<Coordinate>> {\n        let mut centroids = Vec::with_capacity(self.config.k);\n        let mut rng = rand::thread_rng();\n        \n        // Choose first centroid randomly\n        let first_index = rng.gen_range(0..points.len());\n        centroids.push(Coordinate {\n            latitude: points[first_index].measurement.value.x(),\n            longitude: points[first_index].measurement.value.y(),\n        });\n        \n        // Choose remaining centroids with probability proportional to squared distance\n        for _ in 1..self.config.k {\n            let distances: Vec<f64> = points.iter()\n                .map(|point| {\n                    centroids.iter()\n                        .map(|centroid| Coordinate::haversine_distance(\n                            centroid.latitude, centroid.longitude,\n                            point.measurement.value.x(), point.measurement.value.y()\n                        ))\n                        .fold(f64::INFINITY, f64::min)\n                        .powi(2)\n                })\n                .collect();\n                \n            let total_distance: f64 = distances.iter().sum();\n            let threshold = rng.gen::<f64>() * total_distance;\n            \n            let mut cumsum = 0.0;\n            for (i, &distance) in distances.iter().enumerate() {\n                cumsum += distance;\n                if cumsum >= threshold {\n                    centroids.push(Coordinate {\n                        latitude: points[i].measurement.value.x(),\n                        longitude: points[i].measurement.value.y(),\n                    });\n                    break;\n                }\n            }\n        }\n        \n        Ok(centroids)\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"k-means-optimization",children:"K-Means Optimization"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"// Automatic K selection using elbow method\npub fn find_optimal_k(points: &[LocationMeasurement], max_k: usize) -> Result<usize> {\n    let mut inertias = Vec::new();\n    \n    for k in 1..=max_k {\n        let config = KMeansConfig {\n            k,\n            max_iterations: 100,\n            convergence_threshold: 1.0,\n            initialization: InitMethod::KMeansPlusPlus,\n        };\n        \n        let clusterer = KMeansClusterer::new(config);\n        let result = clusterer.cluster(points)?;\n        inertias.push(result.inertia);\n    }\n    \n    // Find elbow point (maximum reduction in inertia)\n    let mut max_reduction = 0.0;\n    let mut optimal_k = 2;\n    \n    for i in 1..inertias.len() - 1 {\n        let reduction = inertias[i - 1] - 2.0 * inertias[i] + inertias[i + 1];\n        if reduction > max_reduction {\n            max_reduction = reduction;\n            optimal_k = i + 1;\n        }\n    }\n    \n    Ok(optimal_k)\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"optics-ordering-points-to-identify-clustering-structure",children:"OPTICS (Ordering Points To Identify Clustering Structure)"}),"\n",(0,s.jsx)(e.p,{children:"OPTICS provides hierarchical density-based clustering:"}),"\n",(0,s.jsx)(e.h3,{id:"algorithm-implementation-2",children:"Algorithm Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::optics::*;\n\n#[derive(Debug, Clone)]\npub struct OPTICSConfig {\n    pub min_points: usize,                  // Minimum points for core object\n    pub epsilon: f64,                       // Maximum search radius (meters)\n    pub xi: f64,                           // Steepness threshold for cluster extraction\n}\n\npub struct OPTICSClusterer {\n    config: OPTICSConfig,\n}\n\n#[derive(Debug, Clone)]\npub struct OPTICSResult {\n    pub ordering: Vec<usize>,               // Point ordering\n    pub reachability: Vec<Option<f64>>,     // Reachability distances\n    pub core_distances: Vec<Option<f64>>,   // Core distances\n}\n\nimpl OPTICSClusterer {\n    pub fn cluster(&self, points: &[LocationMeasurement]) -> Result<OPTICSResult> {\n        let mut ordering = Vec::new();\n        let mut processed = vec![false; points.len()];\n        let mut reachability = vec![None; points.len()];\n        let mut core_distances = vec![None; points.len()];\n        \n        // Calculate core distances\n        for (i, point) in points.iter().enumerate() {\n            let neighbors = self.find_neighbors(i, points);\n            if neighbors.len() >= self.config.min_points {\n                core_distances[i] = Some(self.find_kth_distance(i, &neighbors, points));\n            }\n        }\n        \n        // Process all points\n        for i in 0..points.len() {\n            if processed[i] {\n                continue;\n            }\n            \n            self.expand_cluster_order(\n                i, points, &mut processed, &mut ordering,\n                &mut reachability, &core_distances\n            )?;\n        }\n        \n        Ok(OPTICSResult {\n            ordering,\n            reachability,\n            core_distances,\n        })\n    }\n    \n    fn expand_cluster_order(\n        &self,\n        point_idx: usize,\n        points: &[LocationMeasurement],\n        processed: &mut [bool],\n        ordering: &mut Vec<usize>,\n        reachability: &mut [Option<f64>],\n        core_distances: &[Option<f64>],\n    ) -> Result<()> {\n        let mut priority_queue = BinaryHeap::new();\n        processed[point_idx] = true;\n        ordering.push(point_idx);\n        \n        if let Some(core_dist) = core_distances[point_idx] {\n            let neighbors = self.find_neighbors(point_idx, points);\n            self.update_priority_queue(\n                &neighbors, points, core_dist,\n                &mut priority_queue, processed, reachability\n            )?;\n        }\n        \n        while let Some(OrderPoint { index, distance: _ }) = priority_queue.pop() {\n            processed[index] = true;\n            ordering.push(index);\n            \n            if let Some(core_dist) = core_distances[index] {\n                let neighbors = self.find_neighbors(index, points);\n                self.update_priority_queue(\n                    &neighbors, points, core_dist,\n                    &mut priority_queue, processed, reachability\n                )?;\n            }\n        }\n        \n        Ok(())\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"cluster-extraction-from-optics",children:"Cluster Extraction from OPTICS"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"impl OPTICSResult {\n    pub fn extract_clusters(&self, xi: f64) -> Result<Vec<Cluster>> {\n        let mut clusters = Vec::new();\n        let mut steep_up_areas = Vec::new();\n        let mut cluster_starts = Vec::new();\n        \n        // Find steep areas in reachability plot\n        for i in 1..self.reachability.len() {\n            let prev_reach = self.reachability[i - 1].unwrap_or(f64::INFINITY);\n            let curr_reach = self.reachability[i].unwrap_or(f64::INFINITY);\n            \n            // Steep up area (significant increase in reachability)\n            if curr_reach > prev_reach * (1.0 + xi) {\n                steep_up_areas.push(i);\n            }\n            \n            // Steep down area (significant decrease in reachability)\n            if prev_reach > curr_reach * (1.0 + xi) {\n                cluster_starts.push(i);\n            }\n        }\n        \n        // Extract clusters between steep areas\n        for (start_idx, &start) in cluster_starts.iter().enumerate() {\n            let end = steep_up_areas.get(start_idx).copied()\n                .unwrap_or(self.ordering.len());\n                \n            if end - start >= 3 { // Minimum cluster size\n                let cluster_points: Vec<usize> = self.ordering[start..end].to_vec();\n                let centroid = self.calculate_centroid(&cluster_points)?;\n                \n                clusters.push(Cluster::Core {\n                    id: start_idx,\n                    points: cluster_points,\n                    centroid,\n                });\n            }\n        }\n        \n        Ok(clusters)\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"hdbscan-hierarchical-dbscan",children:"HDBSCAN (Hierarchical DBSCAN)"}),"\n",(0,s.jsx)(e.p,{children:"HDBSCAN provides parameter-free hierarchical clustering:"}),"\n",(0,s.jsx)(e.h3,{id:"algorithm-implementation-3",children:"Algorithm Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::hdbscan::*;\n\n#[derive(Debug, Clone)]\npub struct HDBSCANConfig {\n    pub min_cluster_size: usize,            // Minimum cluster size\n    pub min_samples: usize,                 // Minimum samples for core point\n    pub cluster_selection_epsilon: f64,     // Cluster selection threshold\n    pub cluster_selection_method: ClusterSelection,\n}\n\n#[derive(Debug, Clone)]\npub enum ClusterSelection {\n    EOM,    // Excess of Mass\n    Leaf,   // Leaf selection\n}\n\npub struct HDBSCANClusterer {\n    config: HDBSCANConfig,\n}\n\nimpl HDBSCANClusterer {\n    pub fn cluster(&self, points: &[LocationMeasurement]) -> Result<HDBSCANResult> {\n        // 1. Build minimum spanning tree\n        let mst = self.build_minimum_spanning_tree(points)?;\n        \n        // 2. Build cluster hierarchy\n        let hierarchy = self.build_hierarchy(&mst)?;\n        \n        // 3. Extract flat clustering\n        let clusters = self.extract_clusters(&hierarchy)?;\n        \n        // 4. Calculate stability scores\n        let stability_scores = self.calculate_stability(&hierarchy, &clusters)?;\n        \n        Ok(HDBSCANResult {\n            clusters,\n            hierarchy,\n            stability_scores,\n            noise_points: self.identify_noise_points(&clusters, points.len()),\n        })\n    }\n    \n    fn build_minimum_spanning_tree(&self, points: &[LocationMeasurement]) -> Result<MST> {\n        // Use Prim's algorithm to build MST of mutual reachability distances\n        let mut mst = MST::new();\n        let mut visited = vec![false; points.len()];\n        let mut min_edge = vec![(f64::INFINITY, 0); points.len()];\n        \n        min_edge[0] = (0.0, 0);\n        \n        for _ in 0..points.len() {\n            let mut u = usize::MAX;\n            for v in 0..points.len() {\n                if !visited[v] && (u == usize::MAX || min_edge[v].0 < min_edge[u].0) {\n                    u = v;\n                }\n            }\n            \n            visited[u] = true;\n            \n            if min_edge[u].0 != 0.0 {\n                mst.add_edge(min_edge[u].1, u, min_edge[u].0);\n            }\n            \n            for v in 0..points.len() {\n                if !visited[v] {\n                    let mutual_reach_dist = self.mutual_reachability_distance(u, v, points);\n                    if mutual_reach_dist < min_edge[v].0 {\n                        min_edge[v] = (mutual_reach_dist, u);\n                    }\n                }\n            }\n        }\n        \n        Ok(mst)\n    }\n    \n    fn mutual_reachability_distance(\n        &self,\n        i: usize,\n        j: usize,\n        points: &[LocationMeasurement]\n    ) -> f64 {\n        let core_dist_i = self.core_distance(i, points);\n        let core_dist_j = self.core_distance(j, points);\n        let direct_dist = Coordinate::haversine_distance(\n            points[i].measurement.value.x(), points[i].measurement.value.y(),\n            points[j].measurement.value.x(), points[j].measurement.value.y()\n        );\n        \n        core_dist_i.max(core_dist_j).max(direct_dist)\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"performance-comparison",children:"Performance Comparison"}),"\n",(0,s.jsx)(e.h3,{id:"algorithm-characteristics",children:"Algorithm Characteristics"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Algorithm"}),(0,s.jsx)(e.th,{children:"Time Complexity"}),(0,s.jsx)(e.th,{children:"Space Complexity"}),(0,s.jsx)(e.th,{children:"Best Use Case"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"DBSCAN"}),(0,s.jsx)(e.td,{children:"O(n log n)"}),(0,s.jsx)(e.td,{children:"O(n)"}),(0,s.jsx)(e.td,{children:"Dense, irregular clusters"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"K-Means"}),(0,s.jsx)(e.td,{children:"O(nkt)"}),(0,s.jsx)(e.td,{children:"O(nk)"}),(0,s.jsx)(e.td,{children:"Spherical, balanced clusters"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"OPTICS"}),(0,s.jsx)(e.td,{children:"O(n\xb2)"}),(0,s.jsx)(e.td,{children:"O(n)"}),(0,s.jsx)(e.td,{children:"Hierarchical analysis"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"HDBSCAN"}),(0,s.jsx)(e.td,{children:"O(n\xb2 log n)"}),(0,s.jsx)(e.td,{children:"O(n\xb2)"}),(0,s.jsx)(e.td,{children:"Varying density clusters"})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use std::time::Instant;\n\nfn benchmark_clustering_algorithms(points: &[LocationMeasurement]) -> BenchmarkResults {\n    let mut results = BenchmarkResults::new();\n    \n    // DBSCAN benchmark\n    let start = Instant::now();\n    let dbscan = DBSCANClusterer::new(DBSCANConfig::default());\n    let _clusters = dbscan.cluster(points).unwrap();\n    results.dbscan_time = start.elapsed();\n    \n    // K-Means benchmark\n    let start = Instant::now();\n    let kmeans = KMeansClusterer::new(KMeansConfig::default());\n    let _clusters = kmeans.cluster(points).unwrap();\n    results.kmeans_time = start.elapsed();\n    \n    // OPTICS benchmark\n    let start = Instant::now();\n    let optics = OPTICSClusterer::new(OPTICSConfig::default());\n    let _result = optics.cluster(points).unwrap();\n    results.optics_time = start.elapsed();\n    \n    // HDBSCAN benchmark (for smaller datasets)\n    if points.len() <= 1000 {\n        let start = Instant::now();\n        let hdbscan = HDBSCANClusterer::new(HDBSCANConfig::default());\n        let _result = hdbscan.cluster(points).unwrap();\n        results.hdbscan_time = start.elapsed();\n    }\n    \n    results\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"spatial-indexing",children:"Spatial Indexing"}),"\n",(0,s.jsx)(e.h3,{id:"kd-tree-for-fast-neighbor-queries",children:"KD-Tree for Fast Neighbor Queries"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::spatial::kdtree::*;\n\npub struct SpatialIndex {\n    kdtree: KDTree,\n    points: Vec<LocationMeasurement>,\n}\n\nimpl SpatialIndex {\n    pub fn new(points: Vec<LocationMeasurement>) -> Self {\n        let mut kdtree = KDTree::new();\n        \n        for (i, point) in points.iter().enumerate() {\n            kdtree.insert([\n                point.measurement.value.x() as f64 / 10_000_000.0,  // Convert to decimal degrees\n                point.measurement.value.y() as f64 / 10_000_000.0,\n            ], i);\n        }\n        \n        Self { kdtree, points }\n    }\n    \n    pub fn find_neighbors(&self, center: &LocationMeasurement, radius: f64) -> Vec<usize> {\n        let center_coords = [\n            center.measurement.value.x() as f64 / 10_000_000.0,\n            center.measurement.value.y() as f64 / 10_000_000.0,\n        ];\n        \n        // Convert radius from meters to approximate degrees\n        let radius_degrees = radius / 111_320.0; // Approximate meters per degree\n        \n        self.kdtree.within_radius(&center_coords, radius_degrees)\n    }\n    \n    pub fn k_nearest(&self, center: &LocationMeasurement, k: usize) -> Vec<(usize, f64)> {\n        let center_coords = [\n            center.measurement.value.x() as f64 / 10_000_000.0,\n            center.measurement.value.y() as f64 / 10_000_000.0,\n        ];\n        \n        self.kdtree.k_nearest(&center_coords, k)\n            .into_iter()\n            .map(|(idx, euclidean_dist)| {\n                // Calculate actual haversine distance\n                let actual_distance = Coordinate::haversine_distance(\n                    center.measurement.value.x(), center.measurement.value.y(),\n                    self.points[idx].measurement.value.x(), self.points[idx].measurement.value.y()\n                );\n                (idx, actual_distance)\n            })\n            .collect()\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"integration-examples",children:"Integration Examples"}),"\n",(0,s.jsx)(e.h3,{id:"adaptive-clustering",children:"Adaptive Clustering"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"use olocus_location::clustering::adaptive::*;\n\npub struct AdaptiveClusterer {\n    spatial_index: SpatialIndex,\n    algorithms: Vec<Box<dyn ClusteringAlgorithm>>,\n}\n\nimpl AdaptiveClusterer {\n    pub fn cluster_adaptive(&self, points: &[LocationMeasurement]) -> Result<Vec<Cluster>> {\n        // Analyze data characteristics\n        let stats = self.analyze_data_characteristics(points);\n        \n        // Select optimal algorithm based on characteristics\n        let algorithm = match stats.density_distribution {\n            DensityDistribution::Uniform => &self.algorithms[0], // K-Means\n            DensityDistribution::Varying => &self.algorithms[1], // HDBSCAN\n            DensityDistribution::Sparse => &self.algorithms[2],  // DBSCAN\n        };\n        \n        algorithm.cluster(points)\n    }\n    \n    fn analyze_data_characteristics(&self, points: &[LocationMeasurement]) -> DataCharacteristics {\n        let mut densities = Vec::new();\n        \n        // Sample density at various points\n        for i in (0..points.len()).step_by(points.len() / 20) {\n            let neighbors = self.spatial_index.find_neighbors(&points[i], 100.0);\n            densities.push(neighbors.len() as f64 / (std::f64::consts::PI * 100.0 * 100.0));\n        }\n        \n        let mean_density = densities.iter().sum::<f64>() / densities.len() as f64;\n        let density_variance = densities.iter()\n            .map(|&d| (d - mean_density).powi(2))\n            .sum::<f64>() / densities.len() as f64;\n            \n        DataCharacteristics {\n            point_count: points.len(),\n            mean_density,\n            density_variance,\n            density_distribution: if density_variance < mean_density * 0.1 {\n                DensityDistribution::Uniform\n            } else if density_variance > mean_density {\n                DensityDistribution::Varying\n            } else {\n                DensityDistribution::Sparse\n            },\n        }\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"stream-processing",children:"Stream Processing"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:'use tokio_stream::StreamExt;\n\nasync fn process_location_stream_with_clustering() -> Result<()> {\n    let mut location_buffer = Vec::new();\n    let mut clusterer = DBSCANClusterer::new(DBSCANConfig::default());\n    let mut stream = get_location_stream().await?;\n    \n    while let Some(location) = stream.next().await {\n        location_buffer.push(location?);\n        \n        // Process in batches of 100 locations\n        if location_buffer.len() >= 100 {\n            let clusters = clusterer.cluster(&location_buffer)?;\n            \n            // Process identified clusters\n            for cluster in clusters {\n                if let Cluster::Core { id, points, centroid } = cluster {\n                    println!("New cluster {} with {} points at {:.6},{:.6}", \n                        id, points.len(), centroid.latitude, centroid.longitude);\n                    \n                    // Create visit block for significant clusters\n                    if points.len() >= 5 {\n                        let visit_block = create_visit_block_from_cluster(&cluster)?;\n                        store_block(visit_block).await?;\n                    }\n                }\n            }\n            \n            // Keep sliding window\n            location_buffer.drain(0..50); // Remove older half\n        }\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,s.jsx)(e.h2,{id:"testing--validation",children:"Testing & Validation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"#[cfg(test)]\nmod clustering_tests {\n    use super::*;\n    \n    #[test]\n    fn test_dbscan_with_known_clusters() {\n        let points = create_test_clusters();\n        let config = DBSCANConfig {\n            epsilon: 50.0,\n            min_points: 3,\n            distance_metric: DistanceMetric::Haversine,\n        };\n        \n        let clusterer = DBSCANClusterer::new(config);\n        let clusters = clusterer.cluster(&points).unwrap();\n        \n        // Should find exactly 2 clusters\n        let core_clusters: Vec<_> = clusters.into_iter()\n            .filter(|c| matches!(c, Cluster::Core { .. }))\n            .collect();\n            \n        assert_eq!(core_clusters.len(), 2);\n    }\n    \n    #[test]\n    fn test_kmeans_convergence() {\n        let points = create_test_data(100);\n        let config = KMeansConfig {\n            k: 5,\n            max_iterations: 100,\n            convergence_threshold: 1.0,\n            initialization: InitMethod::KMeansPlusPlus,\n        };\n        \n        let clusterer = KMeansClusterer::new(config);\n        let result = clusterer.cluster(&points).unwrap();\n        \n        // Should converge within reasonable iterations\n        assert!(result.iterations < 50);\n        assert!(result.inertia > 0.0);\n    }\n    \n    fn create_test_clusters() -> Vec<LocationMeasurement> {\n        let mut points = Vec::new();\n        \n        // Cluster 1: Around downtown SF\n        for _ in 0..10 {\n            let lat = 37.7749 + (rand::random::<f64>() - 0.5) * 0.001;\n            let lon = -122.4194 + (rand::random::<f64>() - 0.5) * 0.001;\n            points.push(create_test_location(lat, lon));\n        }\n        \n        // Cluster 2: Around Mission district\n        for _ in 0..8 {\n            let lat = 37.7599 + (rand::random::<f64>() - 0.5) * 0.001;\n            let lon = -122.4148 + (rand::random::<f64>() - 0.5) * 0.001;\n            points.push(create_test_location(lat, lon));\n        }\n        \n        // Noise points\n        for _ in 0..5 {\n            let lat = 37.7000 + rand::random::<f64>() * 0.1;\n            let lon = -122.5000 + rand::random::<f64>() * 0.1;\n            points.push(create_test_location(lat, lon));\n        }\n        \n        points\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"configuration-recommendations",children:"Configuration Recommendations"}),"\n",(0,s.jsx)(e.h3,{id:"data-size-guidelines",children:"Data Size Guidelines"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-rust",children:"// Small datasets (< 1000 points)\nif points.len() < 1000 {\n    return ClusteringAlgorithm::HDBSCAN {\n        min_cluster_size: 3,\n        min_samples: 2,\n        cluster_selection_epsilon: 0.0,\n    };\n}\n\n// Medium datasets (1000 - 10000 points)  \nif points.len() < 10000 {\n    return ClusteringAlgorithm::DBSCAN {\n        epsilon: determine_optimal_epsilon(points),\n        min_points: 4,\n    };\n}\n\n// Large datasets (> 10000 points)\nClusteringAlgorithm::KMeans {\n    k: estimate_optimal_k(points),\n    max_iterations: 100,\n    convergence_threshold: 1.0,\n    initialization: InitMethod::KMeansPlusPlus,\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/extensions/location/tracking",children:"GPS Tracking"})," - Coordinate systems and measurement"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/extensions/location/visit-detection",children:"Visit Detection"})," - Using clustering for visit detection"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/extensions/location/privacy-obfuscation",children:"Privacy & Obfuscation"})," - Privacy-preserving clustering"]}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(u,{...n})}):u(n)}}}]);